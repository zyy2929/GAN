{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4297, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ImageDir</th>\n",
       "      <th>StudyDate_DICOM</th>\n",
       "      <th>StudyID</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>PatientBirth</th>\n",
       "      <th>PatientSex_DICOM</th>\n",
       "      <th>ViewPosition_DICOM</th>\n",
       "      <th>Projection</th>\n",
       "      <th>...</th>\n",
       "      <th>ExposureTime</th>\n",
       "      <th>RelativeXRayExposure_DICOM</th>\n",
       "      <th>ReportID</th>\n",
       "      <th>Report</th>\n",
       "      <th>MethodLabel</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Localizations</th>\n",
       "      <th>LabelsLocalizationsBySentence</th>\n",
       "      <th>labelCUIS</th>\n",
       "      <th>LocalizationsCUIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34309</th>\n",
       "      <td>34309</td>\n",
       "      <td>70275445455146300323895499528986761833_weyugq.png</td>\n",
       "      <td>54</td>\n",
       "      <td>20150504</td>\n",
       "      <td>70275445455146300323895499528986761833</td>\n",
       "      <td>18051150532401968054594246134926799558</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>493</td>\n",
       "      <td>4911343</td>\n",
       "      <td>. . cardiomegali . . . hili prominent probabl...</td>\n",
       "      <td>Physician</td>\n",
       "      <td>['alveolar pattern', 'cardiomegaly', 'vascular...</td>\n",
       "      <td>['loc hilar', 'loc cardiac', 'loc bilateral']</td>\n",
       "      <td>[['alveolar pattern', 'interstitial pattern', ...</td>\n",
       "      <td>['C1332240' 'C0018800' 'C2073538']</td>\n",
       "      <td>['C0205150' 'C1522601' 'C0238767']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34310</th>\n",
       "      <td>34310</td>\n",
       "      <td>70275445455146300323895499528986761833_vgvloc.png</td>\n",
       "      <td>54</td>\n",
       "      <td>20150504</td>\n",
       "      <td>70275445455146300323895499528986761833</td>\n",
       "      <td>18051150532401968054594246134926799558</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PA</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>419</td>\n",
       "      <td>4911343</td>\n",
       "      <td>. . cardiomegali . . . hili prominent probabl...</td>\n",
       "      <td>Physician</td>\n",
       "      <td>['alveolar pattern', 'cardiomegaly', 'vascular...</td>\n",
       "      <td>['loc hilar', 'loc cardiac', 'loc bilateral']</td>\n",
       "      <td>[['alveolar pattern', 'interstitial pattern', ...</td>\n",
       "      <td>['C1332240' 'C0018800' 'C2073538']</td>\n",
       "      <td>['C0205150' 'C1522601' 'C0238767']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34311</th>\n",
       "      <td>34311</td>\n",
       "      <td>104622976193615198495252632114676975389_croa5e...</td>\n",
       "      <td>54</td>\n",
       "      <td>20141016</td>\n",
       "      <td>104622976193615198495252632114676975389</td>\n",
       "      <td>45278616897451567908077362313999529509</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1550</td>\n",
       "      <td>4777059</td>\n",
       "      <td>espondilosis dorsal . sign radiolog epoc .</td>\n",
       "      <td>Physician</td>\n",
       "      <td>['vertebral degenerative changes', 'COPD signs']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[['vertebral degenerative changes'], ['COPD si...</td>\n",
       "      <td>['C4290224' 'C0024117']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34312</th>\n",
       "      <td>34312</td>\n",
       "      <td>104622976193615198495252632114676975389_cfm3t6...</td>\n",
       "      <td>54</td>\n",
       "      <td>20141016</td>\n",
       "      <td>104622976193615198495252632114676975389</td>\n",
       "      <td>45278616897451567908077362313999529509</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PA</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>121</td>\n",
       "      <td>4777059</td>\n",
       "      <td>espondilosis dorsal . sign radiolog epoc .</td>\n",
       "      <td>Physician</td>\n",
       "      <td>['vertebral degenerative changes', 'COPD signs']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[['vertebral degenerative changes'], ['COPD si...</td>\n",
       "      <td>['C4290224' 'C0024117']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34313</th>\n",
       "      <td>34313</td>\n",
       "      <td>184980198091600191287825339126867748451_kkyqir...</td>\n",
       "      <td>54</td>\n",
       "      <td>20170502</td>\n",
       "      <td>184980198091600191287825339126867748451</td>\n",
       "      <td>154275249989026401528046699870493756394</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>269</td>\n",
       "      <td>5373285</td>\n",
       "      <td>escoliosis . sin hallazg radiolog signific .</td>\n",
       "      <td>Physician</td>\n",
       "      <td>['scoliosis']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[['scoliosis'], ['normal']]</td>\n",
       "      <td>['C0036439']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                            ImageID  \\\n",
       "34309       34309  70275445455146300323895499528986761833_weyugq.png   \n",
       "34310       34310  70275445455146300323895499528986761833_vgvloc.png   \n",
       "34311       34311  104622976193615198495252632114676975389_croa5e...   \n",
       "34312       34312  104622976193615198495252632114676975389_cfm3t6...   \n",
       "34313       34313  184980198091600191287825339126867748451_kkyqir...   \n",
       "\n",
       "       ImageDir  StudyDate_DICOM                                  StudyID  \\\n",
       "34309        54         20150504   70275445455146300323895499528986761833   \n",
       "34310        54         20150504   70275445455146300323895499528986761833   \n",
       "34311        54         20141016  104622976193615198495252632114676975389   \n",
       "34312        54         20141016  104622976193615198495252632114676975389   \n",
       "34313        54         20170502  184980198091600191287825339126867748451   \n",
       "\n",
       "                                     PatientID  PatientBirth PatientSex_DICOM  \\\n",
       "34309   18051150532401968054594246134926799558        1929.0                F   \n",
       "34310   18051150532401968054594246134926799558        1929.0                F   \n",
       "34311   45278616897451567908077362313999529509        1934.0                M   \n",
       "34312   45278616897451567908077362313999529509        1934.0                M   \n",
       "34313  154275249989026401528046699870493756394        1964.0                F   \n",
       "\n",
       "      ViewPosition_DICOM Projection  ... ExposureTime  \\\n",
       "34309                NaN          L  ...            0   \n",
       "34310                NaN         PA  ...            0   \n",
       "34311                NaN          L  ...         None   \n",
       "34312                NaN         PA  ...         None   \n",
       "34313                 PA         PA  ...            8   \n",
       "\n",
       "      RelativeXRayExposure_DICOM ReportID  \\\n",
       "34309                        493  4911343   \n",
       "34310                        419  4911343   \n",
       "34311                       1550  4777059   \n",
       "34312                        121  4777059   \n",
       "34313                        269  5373285   \n",
       "\n",
       "                                                  Report MethodLabel  \\\n",
       "34309   . . cardiomegali . . . hili prominent probabl...   Physician   \n",
       "34310   . . cardiomegali . . . hili prominent probabl...   Physician   \n",
       "34311         espondilosis dorsal . sign radiolog epoc .   Physician   \n",
       "34312         espondilosis dorsal . sign radiolog epoc .   Physician   \n",
       "34313       escoliosis . sin hallazg radiolog signific .   Physician   \n",
       "\n",
       "                                                  Labels  \\\n",
       "34309  ['alveolar pattern', 'cardiomegaly', 'vascular...   \n",
       "34310  ['alveolar pattern', 'cardiomegaly', 'vascular...   \n",
       "34311   ['vertebral degenerative changes', 'COPD signs']   \n",
       "34312   ['vertebral degenerative changes', 'COPD signs']   \n",
       "34313                                      ['scoliosis']   \n",
       "\n",
       "                                       Localizations  \\\n",
       "34309  ['loc hilar', 'loc cardiac', 'loc bilateral']   \n",
       "34310  ['loc hilar', 'loc cardiac', 'loc bilateral']   \n",
       "34311                                             []   \n",
       "34312                                             []   \n",
       "34313                                             []   \n",
       "\n",
       "                           LabelsLocalizationsBySentence  \\\n",
       "34309  [['alveolar pattern', 'interstitial pattern', ...   \n",
       "34310  [['alveolar pattern', 'interstitial pattern', ...   \n",
       "34311  [['vertebral degenerative changes'], ['COPD si...   \n",
       "34312  [['vertebral degenerative changes'], ['COPD si...   \n",
       "34313                        [['scoliosis'], ['normal']]   \n",
       "\n",
       "                                labelCUIS                   LocalizationsCUIS  \n",
       "34309  ['C1332240' 'C0018800' 'C2073538']  ['C0205150' 'C1522601' 'C0238767']  \n",
       "34310  ['C1332240' 'C0018800' 'C2073538']  ['C0205150' 'C1522601' 'C0238767']  \n",
       "34311             ['C4290224' 'C0024117']                                  []  \n",
       "34312             ['C4290224' 'C0024117']                                  []  \n",
       "34313                        ['C0036439']                                  []  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "df = pd.read_csv('/scratch/yz6121/data/csv_file/labels')\n",
    "df.head()\n",
    "df = df[df['ImageDir']==54]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Quadro RTX 8000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1294\n"
     ]
    }
   ],
   "source": [
    "allid = list(df.PatientID)\n",
    "pa = []\n",
    "l = []\n",
    "df = df.reset_index(drop=True)\n",
    "for i in range(len(df)):\n",
    "    ids = df.loc[i].PatientID\n",
    "    view = df.loc[i].Projection\n",
    "    if view == 'PA':\n",
    "        pa.append(ids)\n",
    "    elif view == 'L':\n",
    "        l.append(ids)\n",
    "intersect = list(set(pa).intersection(set(l)))\n",
    "print(len(intersect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa1 = pa.copy()\n",
    "l1 = l.copy()\n",
    "for i in pa:\n",
    "    if i in intersect:\n",
    "        pass\n",
    "    else:\n",
    "        pa1.remove(i)\n",
    "for i in l:\n",
    "    if i in intersect:\n",
    "        pass\n",
    "    else:\n",
    "        l1.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1412 1371\n"
     ]
    }
   ],
   "source": [
    "print(len(pa1), len(l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "temp = Counter(pa1+l1)\n",
    "for i in temp.keys():\n",
    "    if temp[i]>=3:\n",
    "        intersect.remove(i)\n",
    "print(len(intersect))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2396, 36)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ImageDir</th>\n",
       "      <th>StudyDate_DICOM</th>\n",
       "      <th>StudyID</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>PatientBirth</th>\n",
       "      <th>PatientSex_DICOM</th>\n",
       "      <th>ViewPosition_DICOM</th>\n",
       "      <th>Projection</th>\n",
       "      <th>...</th>\n",
       "      <th>ExposureTime</th>\n",
       "      <th>RelativeXRayExposure_DICOM</th>\n",
       "      <th>ReportID</th>\n",
       "      <th>Report</th>\n",
       "      <th>MethodLabel</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Localizations</th>\n",
       "      <th>LabelsLocalizationsBySentence</th>\n",
       "      <th>labelCUIS</th>\n",
       "      <th>LocalizationsCUIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34309</td>\n",
       "      <td>70275445455146300323895499528986761833_weyugq.png</td>\n",
       "      <td>54</td>\n",
       "      <td>20150504</td>\n",
       "      <td>70275445455146300323895499528986761833</td>\n",
       "      <td>18051150532401968054594246134926799558</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>493</td>\n",
       "      <td>4911343</td>\n",
       "      <td>. . cardiomegali . . . hili prominent probabl...</td>\n",
       "      <td>Physician</td>\n",
       "      <td>['alveolar pattern', 'cardiomegaly', 'vascular...</td>\n",
       "      <td>['loc hilar', 'loc cardiac', 'loc bilateral']</td>\n",
       "      <td>[['alveolar pattern', 'interstitial pattern', ...</td>\n",
       "      <td>['C1332240' 'C0018800' 'C2073538']</td>\n",
       "      <td>['C0205150' 'C1522601' 'C0238767']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34310</td>\n",
       "      <td>70275445455146300323895499528986761833_vgvloc.png</td>\n",
       "      <td>54</td>\n",
       "      <td>20150504</td>\n",
       "      <td>70275445455146300323895499528986761833</td>\n",
       "      <td>18051150532401968054594246134926799558</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PA</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>419</td>\n",
       "      <td>4911343</td>\n",
       "      <td>. . cardiomegali . . . hili prominent probabl...</td>\n",
       "      <td>Physician</td>\n",
       "      <td>['alveolar pattern', 'cardiomegaly', 'vascular...</td>\n",
       "      <td>['loc hilar', 'loc cardiac', 'loc bilateral']</td>\n",
       "      <td>[['alveolar pattern', 'interstitial pattern', ...</td>\n",
       "      <td>['C1332240' 'C0018800' 'C2073538']</td>\n",
       "      <td>['C0205150' 'C1522601' 'C0238767']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34311</td>\n",
       "      <td>104622976193615198495252632114676975389_croa5e...</td>\n",
       "      <td>54</td>\n",
       "      <td>20141016</td>\n",
       "      <td>104622976193615198495252632114676975389</td>\n",
       "      <td>45278616897451567908077362313999529509</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1550</td>\n",
       "      <td>4777059</td>\n",
       "      <td>espondilosis dorsal . sign radiolog epoc .</td>\n",
       "      <td>Physician</td>\n",
       "      <td>['vertebral degenerative changes', 'COPD signs']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[['vertebral degenerative changes'], ['COPD si...</td>\n",
       "      <td>['C4290224' 'C0024117']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34312</td>\n",
       "      <td>104622976193615198495252632114676975389_cfm3t6...</td>\n",
       "      <td>54</td>\n",
       "      <td>20141016</td>\n",
       "      <td>104622976193615198495252632114676975389</td>\n",
       "      <td>45278616897451567908077362313999529509</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PA</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>121</td>\n",
       "      <td>4777059</td>\n",
       "      <td>espondilosis dorsal . sign radiolog epoc .</td>\n",
       "      <td>Physician</td>\n",
       "      <td>['vertebral degenerative changes', 'COPD signs']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[['vertebral degenerative changes'], ['COPD si...</td>\n",
       "      <td>['C4290224' 'C0024117']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34314</td>\n",
       "      <td>160006731042698331222002747148174207887_podrlm...</td>\n",
       "      <td>54</td>\n",
       "      <td>20140318</td>\n",
       "      <td>160006731042698331222002747148174207887</td>\n",
       "      <td>337486826146076904612701712453104933105</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4658614</td>\n",
       "      <td>sin hallazg signific .</td>\n",
       "      <td>Physician</td>\n",
       "      <td>['normal']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[['normal'], ['normal']]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            ImageID  ImageDir  \\\n",
       "0       34309  70275445455146300323895499528986761833_weyugq.png        54   \n",
       "1       34310  70275445455146300323895499528986761833_vgvloc.png        54   \n",
       "2       34311  104622976193615198495252632114676975389_croa5e...        54   \n",
       "3       34312  104622976193615198495252632114676975389_cfm3t6...        54   \n",
       "5       34314  160006731042698331222002747148174207887_podrlm...        54   \n",
       "\n",
       "   StudyDate_DICOM                                  StudyID  \\\n",
       "0         20150504   70275445455146300323895499528986761833   \n",
       "1         20150504   70275445455146300323895499528986761833   \n",
       "2         20141016  104622976193615198495252632114676975389   \n",
       "3         20141016  104622976193615198495252632114676975389   \n",
       "5         20140318  160006731042698331222002747148174207887   \n",
       "\n",
       "                                 PatientID  PatientBirth PatientSex_DICOM  \\\n",
       "0   18051150532401968054594246134926799558        1929.0                F   \n",
       "1   18051150532401968054594246134926799558        1929.0                F   \n",
       "2   45278616897451567908077362313999529509        1934.0                M   \n",
       "3   45278616897451567908077362313999529509        1934.0                M   \n",
       "5  337486826146076904612701712453104933105        1942.0                F   \n",
       "\n",
       "  ViewPosition_DICOM Projection  ... ExposureTime RelativeXRayExposure_DICOM  \\\n",
       "0                NaN          L  ...            0                        493   \n",
       "1                NaN         PA  ...            0                        419   \n",
       "2                NaN          L  ...         None                       1550   \n",
       "3                NaN         PA  ...         None                        121   \n",
       "5                NaN          L  ...         None                       None   \n",
       "\n",
       "  ReportID                                             Report MethodLabel  \\\n",
       "0  4911343   . . cardiomegali . . . hili prominent probabl...   Physician   \n",
       "1  4911343   . . cardiomegali . . . hili prominent probabl...   Physician   \n",
       "2  4777059         espondilosis dorsal . sign radiolog epoc .   Physician   \n",
       "3  4777059         espondilosis dorsal . sign radiolog epoc .   Physician   \n",
       "5  4658614                             sin hallazg signific .   Physician   \n",
       "\n",
       "                                              Labels  \\\n",
       "0  ['alveolar pattern', 'cardiomegaly', 'vascular...   \n",
       "1  ['alveolar pattern', 'cardiomegaly', 'vascular...   \n",
       "2   ['vertebral degenerative changes', 'COPD signs']   \n",
       "3   ['vertebral degenerative changes', 'COPD signs']   \n",
       "5                                         ['normal']   \n",
       "\n",
       "                                   Localizations  \\\n",
       "0  ['loc hilar', 'loc cardiac', 'loc bilateral']   \n",
       "1  ['loc hilar', 'loc cardiac', 'loc bilateral']   \n",
       "2                                             []   \n",
       "3                                             []   \n",
       "5                                             []   \n",
       "\n",
       "                       LabelsLocalizationsBySentence  \\\n",
       "0  [['alveolar pattern', 'interstitial pattern', ...   \n",
       "1  [['alveolar pattern', 'interstitial pattern', ...   \n",
       "2  [['vertebral degenerative changes'], ['COPD si...   \n",
       "3  [['vertebral degenerative changes'], ['COPD si...   \n",
       "5                           [['normal'], ['normal']]   \n",
       "\n",
       "                            labelCUIS                   LocalizationsCUIS  \n",
       "0  ['C1332240' 'C0018800' 'C2073538']  ['C0205150' 'C1522601' 'C0238767']  \n",
       "1  ['C1332240' 'C0018800' 'C2073538']  ['C0205150' 'C1522601' 'C0238767']  \n",
       "2             ['C4290224' 'C0024117']                                  []  \n",
       "3             ['C4290224' 'C0024117']                                  []  \n",
       "5                                  []                                  []  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[df['PatientID'].isin(intersect)]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176\n",
      "(2352, 36)\n"
     ]
    }
   ],
   "source": [
    "temp = Counter(list(df.PatientID))\n",
    "intersect1= list(set(list(df.PatientID)))\n",
    "for i in temp.keys():\n",
    "    if temp[i]>=3:\n",
    "        intersect1.remove(i)\n",
    "print(len(intersect1))\n",
    "df = df[df['PatientID'].isin(intersect1)]\n",
    "print(df.shape)\n",
    "df = df.sort_values(by='PatientID')\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(img,cropx,cropy):\n",
    "    y,x = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)    \n",
    "    return img[starty:starty+cropy,startx:startx+cropx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change, new version\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "def Generator_2D_slices_new(df, batchsize,inputKey='dataMR',outputKey='dataCT'): #MR: P view, CT: L view\n",
    "\n",
    "    path_patients='/scratch/yz6121/data/images/'\n",
    "\n",
    "    #print(path_patients)\n",
    "\n",
    "    #patients = os.listdir(path_patients)#every file  is a hdf5 patient\n",
    "    pa_view = df[df['Projection']=='PA']\n",
    "    l_view = df[df['Projection']=='L']\n",
    "\n",
    "    while True:\n",
    "        #for idx,namepatient in enumerate(patients):\n",
    "        for i in range(0,len(df),2):\n",
    "            view_1 = df.loc[i].Projection\n",
    "            #view_2 = df.loc[i+1].Projection\n",
    "            location_1 = path_patients+df.loc[i].ImageID\n",
    "            location_2 = path_patients+df.loc[i+1].ImageID\n",
    "            if view_1 == 'PA':\n",
    "                dataMR = imageio.imread(location_1)\n",
    "                dataCT = imageio.imread(location_2)\n",
    "            else:\n",
    "                dataCT = imageio.imread(location_1)\n",
    "                dataMR = imageio.imread(location_2)\n",
    "            #print('check here 2',dataMR.shape, dataCT.shape)\n",
    "            height = min(dataCT.shape[0],dataMR.shape[0])\n",
    "            width = min(dataCT.shape[1],dataMR.shape[1])\n",
    "            #dataCT = transform.resize(dataCT, (2096, 2096)) #resize\n",
    "            #dataMR = transform.resize(dataMR, (2096, 2096))\n",
    "            height = 512\n",
    "            width = 1024\n",
    "            \n",
    "            dataCT = crop_center(dataCT, width, height)\n",
    "            dataMR = crop_center(dataMR, width, height)\n",
    "            \n",
    "            dataCT = np.expand_dims(dataCT, axis = 0)\n",
    "            dataMR = np.expand_dims(dataMR, axis = 0)\n",
    "            dataMR = np.expand_dims(dataMR, axis = 3)\n",
    "            #print('datact, data mr shape',dataCT.shape, dataMR.shape)\n",
    "            \n",
    "            yield (dataMR, dataCT)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "import argparse, os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from utils import *\n",
    "from Unet2d_pytorch import UNet, ResUNet, UNet_LRes, ResUNet_LRes, Discriminator\n",
    "from Unet3d_pytorch import UNet3D\n",
    "from nnBuildUnits import CrossEntropy3d, topK_RegLoss, RelativeThreshold_RegLoss, gdl_loss, adjust_learning_rate, calc_gradient_penalty\n",
    "import time\n",
    "import SimpleITK as sitk\n",
    "class Discriminator1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator1,self).__init__()\n",
    "        #you can make abbreviations for conv and fc, this is not necessary\n",
    "        #class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "        self.conv1 = nn.Conv2d(1,32,(9,9))\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32,64,(5,5))\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64,64,(5,5))\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(984064,512)\n",
    "        #self.bn3= nn.BatchNorm1d(6)\n",
    "        self.fc2 = nn.Linear(512,64)\n",
    "        self.fc3 = nn.Linear(64,1)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "#         print 'line 114: x shape: ',x.size()\n",
    "        #x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))),(2,2))#conv->relu->pool\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))#conv->relu->pool\n",
    "\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))#conv->relu->pool\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)),(2,2))#conv->relu->pool\n",
    "        \n",
    "        #print('x.shape',x.shape)\n",
    "\n",
    "        x = x.view(-1,self.num_of_flat_features(x))\n",
    "        #return x\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        #x = F.sigmoid(x)\n",
    "        #print 'min,max,mean of x in 0st layer',x.min(),x.max(),x.mean()\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def num_of_flat_features(self,x):\n",
    "        size=x.size()[1:]#we donot consider the batch dimension\n",
    "        num_features=1\n",
    "        for s in size:\n",
    "            num_features*=s\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(RT_th=0.005, batchSize=32, cuda=True, decLREvery=1000, dropout_rate=0.2, gdlNorm=2, gpuID=1, how2normalize=6, isAdLoss=True, isGDL=False, isMultiSource=False, isWDist=False, lambda_AD=0.05, lambda_D_WGAN_GP=10, lambda_gdl=0.05, lossBase=1, lr=0.005, lrDecRate=0.5, lrDecRate_netD=0.1, lr_netD=0.005, momentum=0.9, numOfChannel_allSource=1, numOfChannel_singleSource=1, numofIters=200000, prefixModelName='/scratch/yz6121/model/is/gan', prefixPredictedFN='preSub1_pet_BatchAug_sNorm_resunet_dp_lres_bn_lr5e3_lrdec_base1_lossL1_lossGDL0p05_0705_', pretrained='', resume='', saveModelEvery=5000, showTestPerformanceEvery=500, showTrainLossEvery=100, showValPerformanceEvery=100, start_epoch=1, test_gt_file_name='sub13_ct.hdr', test_input_file_name='sub13_mr.hdr', threads=1, weight_decay=0.0001, whichLoss=1, whichNet=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/yz6121/code/is/medSynthesisV1/utils.py:897: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  xavier(m.weight.data)\n",
      "/scratch/yz6121/code/is/medSynthesisV1/Unet2d_pytorch.py:21: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(self.conv.weight, gain = np.sqrt(2.0))\n",
      "/scratch/yz6121/code/is/medSynthesisV1/Unet2d_pytorch.py:22: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.conv.bias,0)\n",
      "/scratch/yz6121/code/is/medSynthesisV1/Unet2d_pytorch.py:23: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(self.conv2.weight, gain = np.sqrt(2.0))\n",
      "/scratch/yz6121/code/is/medSynthesisV1/Unet2d_pytorch.py:24: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.conv2.bias,0)\n",
      "/scratch/yz6121/code/is/medSynthesisV1/Unet2d_pytorch.py:76: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(self.up.weight, gain = np.sqrt(2.0))\n",
      "/scratch/yz6121/code/is/medSynthesisV1/Unet2d_pytorch.py:77: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.up.bias,0)\n",
      "/scratch/yz6121/code/is/medSynthesisV1/Unet2d_pytorch.py:78: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(self.conv.weight, gain = np.sqrt(2.0))\n",
      "/scratch/yz6121/code/is/medSynthesisV1/Unet2d_pytorch.py:79: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.conv.bias,0)\n",
      "/scratch/yz6121/code/is/medSynthesisV1/Unet2d_pytorch.py:80: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(self.conv2.weight, gain = np.sqrt(2.0))\n",
      "/scratch/yz6121/code/is/medSynthesisV1/Unet2d_pytorch.py:81: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.conv2.bias,0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of params is \n",
      "90\n",
      "size of params is \n",
      "torch.Size([64, 1, 3, 3])\n",
      "okay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************\n",
      "time now is: Wed Mar 17 08:23:19 2021\n",
      "average running loss for generator between iter [1, 100] is: 30730.93164\n",
      "lossG_G is 29791.04297 respectively.\n",
      "loss_real is  tensor(100., device='cuda:0') loss_fake is  tensor(0., device='cuda:0') outputD_real is tensor([[0.]], device='cuda:0')\n",
      "loss for discriminator is 100.000000\n",
      "lossG_D for discriminator is 5.000000\n",
      "cost time for iter [1, 100] is 175.93\n",
      "************************************************\n",
      ".......come to validation stage: iter 100 ........\n",
      "lossG_G is 29078.46484.\n",
      "************************************************\n",
      "time now is: Wed Mar 17 08:26:12 2021\n",
      "average running loss for generator between iter [101, 200] is: 30915.63867\n",
      "lossG_G is 29156.08203 respectively.\n",
      "loss_real is  tensor(100., device='cuda:0') loss_fake is  tensor(0., device='cuda:0') outputD_real is tensor([[0.]], device='cuda:0')\n",
      "loss for discriminator is 100.000000\n",
      "lossG_D for discriminator is 5.000000\n",
      "cost time for iter [101, 200] is 172.75\n",
      "************************************************\n",
      ".......come to validation stage: iter 200 ........\n",
      "lossG_G is 35854.92969.\n",
      "************************************************\n",
      "time now is: Wed Mar 17 08:29:03 2021\n",
      "average running loss for generator between iter [201, 300] is: 29943.95898\n",
      "lossG_G is 31123.59570 respectively.\n",
      "loss_real is  tensor(100., device='cuda:0') loss_fake is  tensor(0., device='cuda:0') outputD_real is tensor([[0.]], device='cuda:0')\n",
      "loss for discriminator is 100.000000\n",
      "lossG_D for discriminator is 5.000000\n",
      "cost time for iter [201, 300] is 170.91\n",
      "************************************************\n",
      ".......come to validation stage: iter 300 ........\n",
      "lossG_G is 27592.94141.\n",
      "************************************************\n",
      "time now is: Wed Mar 17 08:32:03 2021\n",
      "average running loss for generator between iter [301, 400] is: 30322.60742\n",
      "lossG_G is 28797.65625 respectively.\n",
      "loss_real is  tensor(100., device='cuda:0') loss_fake is  tensor(0., device='cuda:0') outputD_real is tensor([[0.]], device='cuda:0')\n",
      "loss for discriminator is 100.000000\n",
      "lossG_D for discriminator is 5.000000\n",
      "cost time for iter [301, 400] is 179.45\n",
      "************************************************\n",
      ".......come to validation stage: iter 400 ........\n",
      "lossG_G is 32657.48633.\n",
      "************************************************\n",
      "time now is: Wed Mar 17 08:34:56 2021\n",
      "average running loss for generator between iter [401, 500] is: 29257.08398\n",
      "lossG_G is 26373.64453 respectively.\n",
      "loss_real is  tensor(100., device='cuda:0') loss_fake is  tensor(0., device='cuda:0') outputD_real is tensor([[0.]], device='cuda:0')\n",
      "loss for discriminator is 100.000000\n",
      "lossG_D for discriminator is 5.000000\n",
      "cost time for iter [401, 500] is 173.41\n",
      "************************************************\n",
      ".......come to validation stage: iter 500 ........\n",
      "lossG_G is 31695.31055.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (1024 x 8). Kernel size: (9 x 9). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b8cb01a994cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpuID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-b8cb01a994cf>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0moutputD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#here!################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0;31m#print(outputD_real.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0moutputD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputD_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-0f28d84f6f30>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#         print 'line 114: x shape: ',x.size()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))),(2,2))#conv->relu->pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#conv->relu->pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#conv->relu->pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 419\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (1024 x 8). Kernel size: (9 x 9). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "import argparse, os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from utils import *\n",
    "from Unet2d_pytorch import UNet, ResUNet, UNet_LRes, ResUNet_LRes, Discriminator\n",
    "from Unet3d_pytorch import UNet3D\n",
    "from nnBuildUnits import CrossEntropy3d, topK_RegLoss, RelativeThreshold_RegLoss, gdl_loss, adjust_learning_rate, calc_gradient_penalty\n",
    "import time\n",
    "import SimpleITK as sitk\n",
    "import pickle\n",
    "\n",
    "inputs_test = []\n",
    "exinputs_test = []\n",
    "labels_test = []\n",
    "outputG_test = []\n",
    "\n",
    "# Training settings\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"PyTorch InfantSeg\")\n",
    "parser.add_argument(\"--gpuID\", type=int, default=1, help=\"how to normalize the data\")\n",
    "parser.add_argument(\"--isAdLoss\", action=\"store_true\", help=\"is adversarial loss used?\", default=True)#\n",
    "parser.add_argument(\"--isWDist\", action=\"store_true\", help=\"is adversarial loss with WGAN-GP distance?\", default=False)\n",
    "parser.add_argument(\"--lambda_AD\", default=0.05, type=float, help=\"weight for AD loss, Default: 0.05\")\n",
    "parser.add_argument(\"--lambda_D_WGAN_GP\", default=10, type=float, help=\"weight for gradient penalty of WGAN-GP, Default: 10\")\n",
    "parser.add_argument(\"--how2normalize\", type=int, default=6, help=\"how to normalize the data\")\n",
    "parser.add_argument(\"--whichLoss\", type=int, default=1, help=\"which loss to use: 1. LossL1, 2. lossRTL1, 3. MSE (default)\")\n",
    "parser.add_argument(\"--isGDL\", action=\"store_true\", help=\"do we use GDL loss?\", default=False)#\n",
    "parser.add_argument(\"--gdlNorm\", default=2, type=int, help=\"p-norm for the gdl loss, Default: 2\")\n",
    "parser.add_argument(\"--lambda_gdl\", default=0.05, type=float, help=\"Weight for gdl loss, Default: 0.05\")\n",
    "parser.add_argument(\"--whichNet\", type=int, default=1, help=\"which loss to use: 1. UNet, 2. ResUNet, 3. UNet_LRes and 4. ResUNet_LRes (default, 3)\")\n",
    "parser.add_argument(\"--lossBase\", type=int, default=1, help=\"The base to multiply the lossG_G, Default (1)\")\n",
    "parser.add_argument(\"--batchSize\", type=int, default=32, help=\"training batch size\")\n",
    "parser.add_argument(\"--isMultiSource\", action=\"store_true\", help=\"is multiple modality used?\", default=False)\n",
    "parser.add_argument(\"--numOfChannel_singleSource\", type=int, default=1, help=\"# of channels for a 2D patch for the main modality (Default, 5)\")\n",
    "parser.add_argument(\"--numOfChannel_allSource\", type=int, default=1, help=\"# of channels for a 2D patch for all the concatenated modalities (Default, 5)\")\n",
    "parser.add_argument(\"--numofIters\", type=int, default=200000, help=\"number of iterations to train for\") #200000\n",
    "parser.add_argument(\"--showTrainLossEvery\", type=int, default=100, help=\"number of iterations to show train loss\")\n",
    "parser.add_argument(\"--saveModelEvery\", type=int, default=5000, help=\"number of iterations to save the model\")\n",
    "parser.add_argument(\"--showValPerformanceEvery\", type=int, default=100, help=\"number of iterations to show validation performance\")\n",
    "parser.add_argument(\"--showTestPerformanceEvery\", type=int, default=500, help=\"number of iterations to show test performance\")\n",
    "parser.add_argument(\"--lr\", type=float, default=5e-3, help=\"Learning Rate. Default=1e-4\")\n",
    "parser.add_argument(\"--lr_netD\", type=float, default=5e-3, help=\"Learning Rate for discriminator. Default=5e-3\")\n",
    "parser.add_argument(\"--dropout_rate\", default=0.2, type=float, help=\"prob to drop neurons to zero: 0.2\")\n",
    "parser.add_argument(\"--decLREvery\", type=int, default=1000, help=\"Sets the learning rate to the initial LR decayed by momentum every n iterations, Default: n=40000\")\n",
    "parser.add_argument(\"--lrDecRate\", type=float, default=0.5, help=\"The weight for decreasing learning rate of netG Default=0.5\")\n",
    "parser.add_argument(\"--lrDecRate_netD\", type=float, default=0.1, help=\"The weight for decreasing learning rate of netD. Default=0.1\")\n",
    "parser.add_argument(\"--cuda\", action=\"store_true\", help=\"Use cuda?\", default=True)\n",
    "parser.add_argument(\"--resume\", default=\"\", type=str, help=\"Path to checkpoint (default: none)\")\n",
    "parser.add_argument(\"--start_epoch\", default=1, type=int, help=\"Manual epoch number (useful on restarts)\")\n",
    "parser.add_argument(\"--threads\", type=int, default=1, help=\"Number of threads for data loader to use, Default: 1\")\n",
    "parser.add_argument(\"--momentum\", default=0.9, type=float, help=\"Momentum, Default: 0.9\")\n",
    "parser.add_argument(\"--weight-decay\", \"--wd\", default=1e-4, type=float, help=\"weight decay, Default: 1e-4\")\n",
    "parser.add_argument(\"--RT_th\", default=0.005, type=float, help=\"Relative thresholding: 0.005\")\n",
    "parser.add_argument(\"--pretrained\", default=\"\", type=str, help=\"path to pretrained model (default: none)\")\n",
    "parser.add_argument(\"--prefixModelName\", default=\"/scratch/yz6121/model/is/gan\", type=str, help=\"prefix of the to-be-saved model name\")\n",
    "parser.add_argument(\"--prefixPredictedFN\", default=\"preSub1_pet_BatchAug_sNorm_resunet_dp_lres_bn_lr5e3_lrdec_base1_lossL1_lossGDL0p05_0705_\", type=str, help=\"prefix of the to-be-saved predicted filename\")\n",
    "parser.add_argument(\"--test_input_file_name\",default='sub13_mr.hdr',type=str, help=\"the input file name for testing subject\")\n",
    "parser.add_argument(\"--test_gt_file_name\",default='sub13_ct.hdr',type=str, help=\"the ground-truth file name for testing subject\") \n",
    "\n",
    "global opt, model \n",
    "opt = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "def main():    \n",
    "    print(opt)  \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    netD = Discriminator1()\n",
    "    netD.apply(weights_init)\n",
    "    netD.cuda()\n",
    "    \n",
    "    optimizerD = optim.Adam(netD.parameters(),lr=opt.lr_netD)\n",
    "    criterion_bce=nn.BCELoss()\n",
    "    criterion_bce.cuda()\n",
    "    \n",
    "    #net=UNet()\n",
    "    if opt.whichNet==1:\n",
    "        net = UNet(in_channel=opt.numOfChannel_allSource, n_classes=1)\n",
    "    elif opt.whichNet==2:\n",
    "        net = ResUNet(in_channel=opt.numOfChannel_allSource, n_classes=1)\n",
    "    elif opt.whichNet==3:\n",
    "        net = UNet_LRes(in_channel=opt.numOfChannel_allSource, n_classes=1)\n",
    "    elif opt.whichNet==4:\n",
    "        net = ResUNet_LRes(in_channel=opt.numOfChannel_allSource, n_classes=1, dp_prob = opt.dropout_rate)\n",
    "    #net.apply(weights_init)\n",
    "    net.cuda()\n",
    "    params = list(net.parameters())\n",
    "    print('len of params is ')\n",
    "    print(len(params))\n",
    "    print('size of params is ')\n",
    "    print(params[0].size())\n",
    "    \n",
    " \n",
    "    \n",
    "    optimizer = optim.Adam(net.parameters(),lr=opt.lr)\n",
    "    criterion_L2 = nn.MSELoss()\n",
    "    criterion_L1 = nn.L1Loss()\n",
    "    criterion_RTL1 = RelativeThreshold_RegLoss(opt.RT_th)\n",
    "    criterion_gdl = gdl_loss(opt.gdlNorm)\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "#     criterion = nn.NLLLoss2d()\n",
    "    \n",
    "    given_weight = torch.cuda.FloatTensor([1,4,4,2])\n",
    "    \n",
    "    criterion_3d = CrossEntropy3d(weight=given_weight)\n",
    "    \n",
    "    criterion_3d = criterion_3d.cuda()\n",
    "    criterion_L2 = criterion_L2.cuda()\n",
    "    criterion_L1 = criterion_L1.cuda()\n",
    "    criterion_RTL1 = criterion_RTL1.cuda()\n",
    "    criterion_gdl = criterion_gdl.cuda()\n",
    "    \n",
    "\n",
    "    if opt.isMultiSource:\n",
    "        data_generator = Generator_2D_slicesV1(path_patients_h5,opt.batchSize, inputKey='dataLPET', segKey='dataCT', contourKey='dataHPET')\n",
    "        data_generator_test = Generator_2D_slicesV1(path_patients_h5_val, opt.batchSize, inputKey='dataLPET', segKey='dataCT', contourKey='dataHPET')\n",
    "    else:\n",
    "        data_generator = Generator_2D_slices_new(df,opt.batchSize,inputKey='dataMR',outputKey='dataCT')\n",
    "        data_generator_test = Generator_2D_slices_new(df,opt.batchSize,inputKey='dataMR',outputKey='dataCT')\n",
    "        print('okay')\n",
    "\n",
    "    #data_generator = Generator_2D_slicesV1(path_patients_h5,opt.batchSize, inputKey='dataLPET', segKey='dataCT', contourKey='dataHPET')\n",
    "    #data_generator_test = Generator_2D_slicesV1(path_patients_h5_val, opt.batchSize, inputKey='dataLPET', segKey='dataCT', contourKey='dataHPET')\n",
    "    if opt.resume:\n",
    "        if os.path.isfile(opt.resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(opt.resume))\n",
    "            checkpoint = torch.load(opt.resume)\n",
    "            net.load_state_dict(checkpoint['model'])\n",
    "            opt.start_epoch = 100000\n",
    "            opt.start_epoch = checkpoint[\"epoch\"] + 1\n",
    "            # net.load_state_dict(checkpoint[\"model\"].state_dict())\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(opt.resume))\n",
    "########### We'd better use dataloader to load a lot of data,and we also should train several epoches############### \n",
    "########### We'd better use dataloader to load a lot of data,and we also should train several epoches############### \n",
    "\n",
    "    running_loss = 0.0\n",
    "    start = time.time()\n",
    "    for iter in range(opt.start_epoch, opt.numofIters+50):\n",
    "        #print('iter %d'%iter)\n",
    "                #print('iter %d'%iter)\n",
    "        if opt.isMultiSource:\n",
    "            inputs, exinputs, labels = next(data_generator)#.next()\n",
    "        else:\n",
    "            inputs, labels = next(data_generator)#.next()         \n",
    "            exinputs = inputs\n",
    "            #print('check here',inputs.shape, labels.shape)  #CHANGE HERE\n",
    "#        inputs, exinputs, labels = data_generator.next()\n",
    "\n",
    "#         xx = np.transpose(inputs,(5,64,64))\n",
    "        inputs = np.transpose(inputs,(0,3,1,2)) #change here: added\n",
    "        #inputs = np.squeeze(inputs) #5x64x64 #change here\n",
    "        exinputs = np.transpose(exinputs,(0,3,1,2)) #change here: added\n",
    "        #exinputs = np.squeeze(exinputs) #5x64x64 #change here\n",
    "#         print 'shape is ....',inputs.shape\n",
    "        #labels = np.squeeze(labels) #64x64 #change here\n",
    "#         labels = labels.astype(int)\n",
    "        \n",
    "        #change here\n",
    "        inputs = inputs.astype(float)\n",
    "        inputs = torch.from_numpy(inputs)\n",
    "        inputs = inputs.float()\n",
    "        exinputs = exinputs.astype(float)\n",
    "        exinputs = torch.from_numpy(exinputs)\n",
    "        exinputs = exinputs.float()\n",
    "        labels = labels.astype(float)\n",
    "        labels = torch.from_numpy(labels)\n",
    "        labels = labels.float()\n",
    "\n",
    "        #inputs = exinputs = torch.randn(1,1,512,512)\n",
    "        #labels = torch.randn(1,512,512)  #CHANGE HERE\n",
    "        #print type(inputs), type(exinputs)  #CHANGE HERE\n",
    "        if opt.isMultiSource:\n",
    "            source = torch.cat((inputs, exinputs),dim=1)\n",
    "        else:\n",
    "            source = inputs\n",
    "        #source = inputs\n",
    "        mid_slice = opt.numOfChannel_singleSource//2\n",
    "        #residual_source = inputs[:, mid_slice, ...]\n",
    "        #inputs = inputs.cuda()\n",
    "        #exinputs = exinputs.cuda()\n",
    "        source = source.cuda()\n",
    "        #residual_source = residual_source.cuda()\n",
    "        labels = labels.cuda()\n",
    "        #we should consider different data to train\n",
    "        \n",
    "        #wrap them into Variable\n",
    "        #source, residual_source, labels = Variable(source),Variable(residual_source), Variable(labels)\n",
    "        source, labels = Variable(source), Variable(labels)\n",
    "        #inputs, exinputs, labels = Variable(inputs),Variable(exinputs), Variable(labels)\n",
    "        \n",
    "        ## (1) update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        #print('source shape',source.shape) #change here, source shape\n",
    "        if opt.isAdLoss:\n",
    "            #outputG = net(source,residual_source) #5x64x64->1*64x64\n",
    "            if opt.whichNet == 3 or opt.whichNet == 4:\n",
    "                outputG = net(source, residual_source)  # 5x64x64->1*64x64\n",
    "            else:\n",
    "                outputG = net(source)  # 5x64x64->1*64x64\n",
    "                \n",
    "            if len(labels.size())==3:\n",
    "                labels = labels.unsqueeze(1)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            outputD_real = netD(labels)   #here!################\n",
    "            #print(outputD_real.shape)\n",
    "            outputD_real = F.sigmoid(outputD_real)\n",
    "            \n",
    "            if len(outputG.size())==3:\n",
    "                outputG = outputG.unsqueeze(1)\n",
    "                \n",
    "            outputD_fake = netD(outputG)\n",
    "            outputD_fake = F.sigmoid(outputD_fake)\n",
    "            netD.zero_grad()\n",
    "            batch_size = inputs.size(0)\n",
    "            real_label = torch.ones(batch_size,1)\n",
    "            real_label = real_label.cuda()\n",
    "            #print(real_label.size())\n",
    "            real_label = Variable(real_label)\n",
    "            #print(outputD_real.size())\n",
    "            loss_real = criterion_bce(outputD_real,real_label)\n",
    "            loss_real.backward()\n",
    "            #train with fake data\n",
    "            fake_label = torch.zeros(batch_size,1)\n",
    "    #         fake_label = torch.FloatTensor(batch_size)\n",
    "    #         fake_label.data.resize_(batch_size).fill_(0)\n",
    "            fake_label = fake_label.cuda()\n",
    "            fake_label = Variable(fake_label)\n",
    "            loss_fake = criterion_bce(outputD_fake,fake_label)\n",
    "            loss_fake.backward()\n",
    "            \n",
    "            lossD = loss_real + loss_fake\n",
    "#             print 'loss_real is ',loss_real.data[0],'loss_fake is ',loss_fake.data[0],'outputD_real is',outputD_real.data[0]\n",
    "#             print('loss for discriminator is %f'%lossD.data[0])\n",
    "            #update network parameters\n",
    "            optimizerD.step()\n",
    "            \n",
    "        if opt.isWDist:\n",
    "            one = torch.FloatTensor([1])\n",
    "            mone = one * -1\n",
    "            one = one.cuda()\n",
    "            mone = mone.cuda()\n",
    "            \n",
    "            netD.zero_grad()\n",
    "            \n",
    "            #outputG = net(source,residual_source) #5x64x64->1*64x64\n",
    "            if opt.whichNet == 3 or opt.whichNet == 4:\n",
    "                outputG = net(source, residual_source)  # 5x64x64->1*64x64\n",
    "            else:\n",
    "                outputG = net(source)  # 5x64x64->1*64x64\n",
    "                \n",
    "            if len(labels.size())==3:\n",
    "                labels = labels.unsqueeze(1)\n",
    "                \n",
    "            outputD_real = netD(labels)\n",
    "            \n",
    "            if len(outputG.size())==3:\n",
    "                outputG = outputG.unsqueeze(1)\n",
    "                \n",
    "            outputD_fake = netD(outputG)\n",
    "\n",
    "            \n",
    "            batch_size = inputs.size(0)\n",
    "            \n",
    "            D_real = outputD_real.mean()\n",
    "            # print D_real\n",
    "            D_real.backward(mone)\n",
    "        \n",
    "        \n",
    "            D_fake = outputD_fake.mean()\n",
    "            D_fake.backward(one)\n",
    "        \n",
    "            gradient_penalty = opt.lambda_D_WGAN_GP*calc_gradient_penalty(netD, labels.data, outputG.data)\n",
    "            gradient_penalty.backward()\n",
    "            \n",
    "            D_cost = D_fake - D_real + gradient_penalty\n",
    "            Wasserstein_D = D_real - D_fake\n",
    "            \n",
    "            optimizerD.step()\n",
    "        \n",
    "        \n",
    "        ## (2) update G network: minimize the L1/L2 loss, maximize the D(G(x))\n",
    "        \n",
    "#         print inputs.data.shape\n",
    "        #outputG = net(source) #here I am not sure whether we should use twice or not\n",
    "        if opt.whichNet == 3 or opt.whichNet == 4:\n",
    "            outputG = net(source, residual_source)  # 5x64x64->1*64x64\n",
    "        else:\n",
    "            outputG = net(source)  # 5x64x64->1*64x64\n",
    "        #outputG = net(source,residual_source) #5x64x64->1*64x64\n",
    "        net.zero_grad()\n",
    "        if opt.whichLoss==1:\n",
    "            #print('loss check',torch.squeeze(outputG).shape, torch.squeeze(labels).shape) #loss check\n",
    "            #print(torch.squeeze(outputG), torch.squeeze(labels))\n",
    "            lossG_G = criterion_L1(torch.squeeze(outputG), torch.squeeze(labels))\n",
    "            #print(lossG_G.shape, lossG_G.data.shape, lossG_G.data) #change here\n",
    "        elif opt.whichLoss==2:\n",
    "            lossG_G = criterion_RTL1(torch.squeeze(outputG), torch.squeeze(labels))\n",
    "        else:\n",
    "            lossG_G = criterion_L2(torch.squeeze(outputG), torch.squeeze(labels))\n",
    "        lossG_G = opt.lossBase * lossG_G\n",
    "        lossG_G.backward(retain_graph=True) #compute gradients\n",
    "\n",
    "        if opt.isGDL:\n",
    "            lossG_gdl = opt.lambda_gdl * criterion_gdl(outputG,torch.unsqueeze(torch.squeeze(labels,1),1))\n",
    "            lossG_gdl.backward() #compute gradients\n",
    "\n",
    "        if opt.isAdLoss:\n",
    "            #we want to fool the discriminator, thus we pretend the label here to be real. Actually, we can explain from the \n",
    "            #angel of equation (note the max and min difference for generator and discriminator)\n",
    "            #outputG = net(inputs)\n",
    "            #outputG = net(source,residual_source) #5x64x64->1*64x64\n",
    "            if opt.whichNet == 3 or opt.whichNet == 4:\n",
    "                outputG = net(source, residual_source)  # 5x64x64->1*64x64\n",
    "            else:\n",
    "                outputG = net(source)  # 5x64x64->1*64x64\n",
    "            \n",
    "            if len(outputG.size())==3:\n",
    "                outputG = outputG.unsqueeze(1)\n",
    "            \n",
    "            outputD = netD(outputG)\n",
    "            outputD = F.sigmoid(outputD)\n",
    "            lossG_D = opt.lambda_AD*criterion_bce(outputD,real_label) #note, for generator, the label for outputG is real, because the G wants to confuse D\n",
    "            lossG_D.backward()\n",
    "            \n",
    "        if opt.isWDist:\n",
    "            #we want to fool the discriminator, thus we pretend the label here to be real. Actually, we can explain from the \n",
    "            #angel of equation (note the max and min difference for generator and discriminator)\n",
    "            #outputG = net(inputs)\n",
    "            #outputG = net(source,residual_source) #5x64x64->1*64x64\n",
    "            if opt.whichNet == 3 or opt.whichNet == 4:\n",
    "                outputG = net(source, residual_source)  # 5x64x64->1*64x64\n",
    "            else:\n",
    "                outputG = net(source)  # 5x64x64->1*64x64\n",
    "            if len(outputG.size())==3:\n",
    "                outputG = outputG.unsqueeze(1)\n",
    "            \n",
    "            outputD_fake = netD(outputG)\n",
    "\n",
    "            outputD_fake = outputD_fake.mean()\n",
    "            \n",
    "            lossG_D = opt.lambda_AD*outputD_fake.mean() #note, for generator, the label for outputG is real, because the G wants to confuse D\n",
    "            lossG_D.backward(mone)\n",
    "        \n",
    "        #for other losses, we can define the loss function following the pytorch tutorial\n",
    "        \n",
    "        optimizer.step() #update network parameters\n",
    "\n",
    "        #print('loss for generator is %f'%lossG.data[0])\n",
    "        #print statistics\n",
    "        running_loss = running_loss + lossG_G.data\n",
    "        #running_loss = running_loss + lossG_G.data[0]\n",
    "\n",
    "        \n",
    "        if iter%opt.showTrainLossEvery==0: #print every 2000 mini-batches\n",
    "            print('************************************************')\n",
    "            print('time now is: ' + time.asctime(time.localtime(time.time())))\n",
    "#             print 'running loss is ',running_loss\n",
    "            print('average running loss for generator between iter [%d, %d] is: %.5f'%(iter - 100 + 1,iter,running_loss/100))\n",
    "            \n",
    "            print('lossG_G is %.5f respectively.'%(lossG_G.data))\n",
    "            ############################################\n",
    "            \n",
    "            if opt.isGDL:\n",
    "                print('loss for GDL loss is %f'%lossG_gdl.data[0])\n",
    "\n",
    "            if opt.isAdLoss:\n",
    "                print('loss_real is ',loss_real.data,'loss_fake is ',loss_fake.data,\n",
    "                      'outputD_real is',outputD_real.data)\n",
    "                print('loss for discriminator is %f'%lossD.data)  \n",
    "                print('lossG_D for discriminator is %f'%lossG_D.data)  \n",
    "\n",
    "            if opt.isWDist:\n",
    "                print('loss_real is ',torch.mean(D_real).data[0],'loss_fake is ',torch.mean(D_fake).data[0])\n",
    "                print('loss for discriminator is %f'%Wasserstein_D.data[0], ' D cost is %f'%D_cost)                \n",
    "                print('lossG_D for discriminator is %f'%lossG_D.data[0])  \n",
    "            \n",
    "  \n",
    "            print('cost time for iter [%d, %d] is %.2f'%(iter - 100 + 1,iter, time.time()-start))\n",
    "            print('************************************************')\n",
    "            running_loss = 0.0\n",
    "            start = time.time()\n",
    "       \n",
    "        if iter%opt.saveModelEvery==0: #save the model\n",
    "            state = {\n",
    "                'epoch': iter+1,\n",
    "                'model': net.state_dict()\n",
    "            }\n",
    "            torch.save(state, opt.prefixModelName+'both_2'+'%d.pt'%iter)\n",
    "            print('save model: '+opt.prefixModelName+'%d.pt'%iter)\n",
    "                   \n",
    "            \n",
    "\n",
    "            if opt.isAdLoss or opt.isWDist:\n",
    "                torch.save(netD.state_dict(), opt.prefixModelName+'both_2'+'_net_D%d.pt'%iter)\n",
    "        if iter%opt.decLREvery==0:\n",
    "            opt.lr = opt.lr*opt.lrDecRate\n",
    "            adjust_learning_rate(optimizer, opt.lr)\n",
    "            if opt.isAdLoss or opt.isWDist:\n",
    "                opt.lr_netD = opt.lr_netD*opt.lrDecRate_netD\n",
    "                adjust_learning_rate(optimizerD, opt.lr_netD)\n",
    "        \n",
    "\n",
    "  \n",
    "        if iter%opt.showValPerformanceEvery==0: #test one subject\n",
    "            with torch.no_grad():\n",
    "            # to test on the validation dataset in the format of h5 \n",
    "#            inputs,exinputs,labels = data_generator_test.next()\n",
    "                if opt.isMultiSource:\n",
    "                    inputs, exinputs, labels = next(data_generator)#.next()\n",
    "                else:\n",
    "                    inputs, labels = next(data_generator)#.next()\n",
    "                    exinputs = inputs\n",
    "\n",
    "                inputs = np.transpose(inputs,(0,3,1,2)) #ADD HERE\n",
    "            #inputs = np.squeeze(inputs) #DELETE HERE\n",
    "\n",
    "                exinputs = np.transpose(exinputs, (0, 3, 1, 2)) #ADD HERE\n",
    "            #exinputs = np.squeeze(exinputs)  # 5x64x64 #DELETE HERE\n",
    "\n",
    "                labels = np.squeeze(labels)\n",
    "            #test\n",
    "                inputs = inputs.astype(float)\n",
    "                inputs = torch.from_numpy(inputs)\n",
    "                inputs = inputs.float()\n",
    "            \n",
    "                inputs_test.append(inputs)\n",
    "            \n",
    "                exinputs = exinputs.astype(float)\n",
    "                exinputs = torch.from_numpy(exinputs)\n",
    "                exinputs = exinputs.float()\n",
    "                exinputs_test.append(exinputs)\n",
    "            \n",
    "                labels = labels.astype(float)\n",
    "                labels = torch.from_numpy(labels)\n",
    "                labels = labels.float()\n",
    "                labels_test.append(labels)\n",
    "            \n",
    "                mid_slice = opt.numOfChannel_singleSource // 2\n",
    "                residual_source = inputs[:, mid_slice, ...]\n",
    "                if opt.isMultiSource:\n",
    "                    source = torch.cat((inputs, exinputs), dim=1)\n",
    "                else:\n",
    "                    source = inputs\n",
    "                source = source.cuda()\n",
    "                residual_source = residual_source.cuda()\n",
    "                labels = labels.cuda()\n",
    "                source,residual_source,labels = Variable(source),Variable(residual_source), Variable(labels)\n",
    "\n",
    "            # source = inputs\n",
    "            #outputG = net(inputs)\n",
    "            #outputG = net(source,residual_source) #5x64x64->1*64x64\n",
    "                if opt.whichNet == 3 or opt.whichNet == 4:\n",
    "                    outputG = net(source, residual_source)  # 5x64x64->1*64x64\n",
    "                else:\n",
    "                    outputG = net(source)  # 5x64x64->1*64x64\n",
    "                outputG_test.append(outputG)  ## results\n",
    "            \n",
    "    \n",
    "            if iter%2000==0:  #save\n",
    "\n",
    "                file=open(r\"./results/inputs_test512_both_2.bin\",\"wb\")\n",
    "                pickle.dump(inputs_test,file) \n",
    "                file.close()\n",
    "            \n",
    "                file=open(r\"./results/exinputs_test512_both_2.bin\",\"wb\")\n",
    "                pickle.dump(exinputs_test,file) \n",
    "                file.close()\n",
    "            \n",
    "                file=open(r\"./results/labels_test512_both_2.bin\",\"wb\")\n",
    "                pickle.dump(labels_test,file) \n",
    "                file.close()\n",
    "            \n",
    "                file=open(r\"./results/outputG_test512_both_2.bin\",\"wb\")\n",
    "                pickle.dump(outputG_test,file) \n",
    "                file.close()\n",
    "          \n",
    "\n",
    "            \n",
    "            if opt.whichLoss == 1:\n",
    "                lossG_G = criterion_L1(torch.squeeze(outputG), torch.squeeze(labels))\n",
    "            elif opt.whichLoss == 2:\n",
    "                lossG_G = criterion_RTL1(torch.squeeze(outputG), torch.squeeze(labels))\n",
    "            else:\n",
    "                lossG_G = criterion_L2(torch.squeeze(outputG), torch.squeeze(labels))\n",
    "            lossG_G = opt.lossBase * lossG_G\n",
    "            print('.......come to validation stage: iter {}'.format(iter),'........')\n",
    "            print('lossG_G is %.5f.'%(lossG_G.data))\n",
    "\n",
    "            if opt.isGDL:\n",
    "                lossG_gdl = criterion_gdl(outputG, torch.unsqueeze(torch.squeeze(labels,1),1))\n",
    "                print('loss for GDL loss is %f'%lossG_gdl.data)\n",
    "\n",
    "    #print('Finished Training')\n",
    "\n",
    "if __name__ == '__main__':   \n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(opt.gpuID)  \n",
    "    main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file=open(r\"./results/outputG_test512_both_1.bin\",\"rb\")\n",
    "mylist=pickle.load(file) \n",
    "print(len(mylist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "outputG_0 = mylist[100]\n",
    "outputG_0 = outputG_0.squeeze()\n",
    "outputG_0 = outputG_0.detach().cpu().numpy()\n",
    "print(outputG_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "imageio.imwrite(r'./results/generator_both_100.jpg',outputG_0)\n",
    "#img = Image.fromarray(outputG_0.astype('uint8'))\n",
    "#img.save('./results/generator_only_100.png')\n",
    "#img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
